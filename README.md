# Flash-Kernels
Use triton/cuda to implement flash attention
