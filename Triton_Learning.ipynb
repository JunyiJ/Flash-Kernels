{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbBgFTUh+yTSDBLDzW8vqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunyiJ/Flash-Kernels/blob/main/Triton_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG0GWmDOyrt3",
        "outputId": "461e8922-dc4f-4c64-fe06-a861cc854b77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n",
            "✅ Flash-Kernels exists. Pulling latest changes...\n",
            "/content/drive/MyDrive/Flash-Kernels\n",
            "Already up to date.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive, userdata\n",
        "import os\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Config (Fill these in)\n",
        "try:\n",
        "    GITHUB_TOKEN = userdata.get('GH_TOKEN')\n",
        "    GITHUB_USER = \"JunyiJ\"\n",
        "    REPO_NAME = \"Flash-Kernels\"\n",
        "except userdata.SecretNotFoundError:\n",
        "    print(\"❌ Secret 'GH_TOKEN' not found. Add it in the 'Secrets' tab (key icon).\")\n",
        "\n",
        "# 3. Clone or Sync\n",
        "%cd /content/drive/MyDrive\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    !git clone https://{GITHUB_USER}:{GITHUB_TOKEN}@github.com/{GITHUB_USER}/{REPO_NAME}.git\n",
        "else:\n",
        "    print(f\"✅ {REPO_NAME} exists. Pulling latest changes...\")\n",
        "    %cd {REPO_NAME}\n",
        "    !git pull\n",
        "\n",
        "# 4. Set Git Identity\n",
        "!git config --global user.email \"jiaojunyi90@gmail.com\"\n",
        "!git config --global user.name \"JunyiJ\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%cd /content/drive/MyDrive/Flash-Kernels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wfisYghzjjF",
        "outputId": "45f6fbad-ec11-4083-927d-8ae23169efe1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Flash-Kernels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 01_vector_add/triton_vec_add.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh7JM_Nz0JE8",
        "outputId": "141f61e8-9104-4c08-cfde-60f7b9463576"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1.3713, 1.3076, 0.4940,  ..., 0.4024, 1.7918, 1.0686], device='cuda:0')\n",
            "tensor([1.3713, 1.3076, 0.4940,  ..., 0.4024, 1.7918, 1.0686], device='cuda:0')\n",
            "The maximum difference between torch and triton is 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 02_matmul/triton_matmul.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JN8nPl0H0K4o",
        "outputId": "ba0a89ab-965f-45e4-f0e5-749f4d084d48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ -0.6089,   5.5000,  -7.8633,  ...,  10.3594,  -2.4434,  -6.9180],\n",
            "        [  7.0000,  16.2656,  26.4688,  ...,  11.8594,   4.5625,  18.3750],\n",
            "        [  3.6777, -15.3125,  -2.0820,  ..., -41.7500,  26.8906, -12.5547],\n",
            "        ...,\n",
            "        [  0.7246,  75.0625, -26.1562,  ...,  26.6875,  -0.7197, -48.0000],\n",
            "        [  6.6484,  -0.7490, -39.2500,  ..., -38.7812, -15.4609, -48.9688],\n",
            "        [ 27.7812,  29.4062,  22.3281,  ...,  14.4922,   5.2344,  23.4844]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "tensor([[ -0.6089,   5.5000,  -7.8633,  ...,  10.3594,  -2.4434,  -6.9180],\n",
            "        [  7.0000,  16.2656,  26.4688,  ...,  11.8594,   4.5625,  18.3750],\n",
            "        [  3.6777, -15.3125,  -2.0820,  ..., -41.7500,  26.8906, -12.5547],\n",
            "        ...,\n",
            "        [  0.7246,  75.0625, -26.1562,  ...,  26.6875,  -0.7197, -48.0000],\n",
            "        [  6.6484,  -0.7490, -39.2500,  ..., -38.7812, -15.4609, -48.9688],\n",
            "        [ 27.7812,  29.4062,  22.3281,  ...,  14.4922,   5.2344,  23.4844]],\n",
            "       device='cuda:0', dtype=torch.float16)\n",
            "The maximum difference between torch and triton is 0.03125\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 03_softmax/triton_softmax.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOEE-P_78HZG",
        "outputId": "6e8049ce-c716-4616-da66-c8968b75358c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0047, 0.0046, 0.0031,  ..., 0.0090, 0.0005, 0.0008],\n",
            "        [0.0017, 0.0061, 0.0023,  ..., 0.0060, 0.0024, 0.0006],\n",
            "        [0.0005, 0.0003, 0.0004,  ..., 0.0002, 0.0019, 0.0047],\n",
            "        ...,\n",
            "        [0.0011, 0.0073, 0.0009,  ..., 0.0010, 0.0035, 0.0007],\n",
            "        [0.0033, 0.0021, 0.0116,  ..., 0.0009, 0.0030, 0.0002],\n",
            "        [0.0030, 0.0017, 0.0004,  ..., 0.0005, 0.0003, 0.0024]],\n",
            "       device='cuda:0')\n",
            "tensor([[0.0047, 0.0046, 0.0031,  ..., 0.0090, 0.0005, 0.0008],\n",
            "        [0.0017, 0.0061, 0.0023,  ..., 0.0060, 0.0024, 0.0006],\n",
            "        [0.0005, 0.0003, 0.0004,  ..., 0.0002, 0.0019, 0.0047],\n",
            "        ...,\n",
            "        [0.0011, 0.0073, 0.0009,  ..., 0.0010, 0.0035, 0.0007],\n",
            "        [0.0033, 0.0021, 0.0116,  ..., 0.0009, 0.0030, 0.0002],\n",
            "        [0.0030, 0.0017, 0.0004,  ..., 0.0005, 0.0003, 0.0024]],\n",
            "       device='cuda:0')\n",
            "The maximum difference between torch and triton is 7.450580596923828e-09\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python 04_flash_attention/triton_flash_attn.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZNPgzyeLO1e",
        "outputId": "d0f0098a-2c55-4bad-e805-79a71ab2bab8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-1.6289e+00,  1.3203e+00,  1.5352e+00,  ..., -3.1270e+00,\n",
            "           -2.8789e+00, -2.0264e-01],\n",
            "          [-1.4160e-01, -7.3486e-02, -4.2310e-01,  ..., -2.2693e-01,\n",
            "            2.3157e-01,  1.3457e+00],\n",
            "          [-8.3691e-01,  6.8262e-01,  7.5732e-01,  ..., -1.7197e+00,\n",
            "           -1.0166e+00,  3.6255e-01],\n",
            "          ...,\n",
            "          [ 6.5880e-03,  2.5620e-02,  1.0150e-01,  ..., -6.5660e-04,\n",
            "           -6.3904e-02,  5.0171e-02],\n",
            "          [-9.5459e-02, -4.0588e-02, -4.1466e-03,  ..., -2.6718e-02,\n",
            "           -7.2083e-02,  4.0985e-02],\n",
            "          [-3.7384e-03, -3.8391e-02,  9.7168e-02,  ..., -5.6580e-02,\n",
            "           -1.1359e-01, -1.3229e-02]],\n",
            "\n",
            "         [[ 2.0462e-02, -1.5664e+00, -9.5020e-01,  ..., -3.1421e-01,\n",
            "           -3.7378e-01,  1.3809e+00],\n",
            "          [ 6.0742e-01, -5.7031e-01, -8.9404e-01,  ...,  2.7539e-01,\n",
            "           -6.0498e-01,  2.1436e-01],\n",
            "          [ 3.5248e-02,  3.1616e-01,  3.5986e-01,  ...,  5.8057e-01,\n",
            "           -1.0029e+00, -8.9062e-01],\n",
            "          ...,\n",
            "          [ 5.3284e-02, -3.6865e-02,  6.1188e-02,  ..., -4.0924e-02,\n",
            "           -3.2104e-02,  5.8502e-02],\n",
            "          [ 1.3123e-01, -3.8971e-02,  4.6875e-02,  ...,  2.5024e-02,\n",
            "           -4.1443e-02,  3.8330e-02],\n",
            "          [ 5.9235e-02, -8.3984e-02,  4.0405e-02,  ...,  6.1264e-03,\n",
            "           -7.9041e-02, -1.6113e-02]],\n",
            "\n",
            "         [[-1.1182e+00,  1.1924e+00,  6.0791e-01,  ...,  2.2339e-01,\n",
            "           -4.9194e-01,  1.1270e+00],\n",
            "          [-3.6914e-01, -8.1104e-01, -2.0154e-01,  ..., -7.6221e-01,\n",
            "            1.2549e+00,  9.5068e-01],\n",
            "          [-3.1787e-01, -1.2080e+00, -2.1960e-01,  ..., -1.0332e+00,\n",
            "            1.5908e+00,  5.7520e-01],\n",
            "          ...,\n",
            "          [-2.8091e-02,  1.3809e-02, -2.7603e-02,  ..., -2.2842e-02,\n",
            "           -2.8183e-02,  3.7956e-03],\n",
            "          [-2.4673e-02,  7.9285e-02, -2.5314e-02,  ..., -1.0284e-02,\n",
            "            5.3040e-02, -9.7473e-02],\n",
            "          [-7.3318e-03, -2.3407e-02,  3.4271e-02,  ..., -1.1108e-02,\n",
            "            6.9885e-02, -4.6356e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7207e-01, -4.9219e-01, -1.1465e+00,  ..., -5.3662e-01,\n",
            "           -4.0283e-01,  3.0615e-01],\n",
            "          [ 2.4927e-01, -3.5645e-01, -9.8047e-01,  ..., -5.0684e-01,\n",
            "           -2.2107e-01,  1.7419e-01],\n",
            "          [-2.4506e-02, -1.4600e-01, -6.7920e-01,  ..., -3.5327e-01,\n",
            "           -7.9285e-02,  1.2219e-01],\n",
            "          ...,\n",
            "          [ 1.2390e-02, -4.0009e-02, -1.0345e-02,  ..., -1.4084e-02,\n",
            "           -3.0640e-02,  5.1147e-02],\n",
            "          [ 3.6743e-02, -1.0242e-01, -3.4058e-02,  ..., -5.2399e-02,\n",
            "           -1.2891e-01,  1.1200e-01],\n",
            "          [ 4.1748e-02, -2.6611e-02, -6.0669e-02,  ...,  3.0960e-02,\n",
            "           -1.1005e-01,  1.3098e-01]],\n",
            "\n",
            "         [[-1.1006e+00, -4.6997e-01,  1.0029e+00,  ...,  4.0991e-01,\n",
            "            1.9824e-01,  6.3867e-01],\n",
            "          [-6.2451e-01, -3.3325e-01,  3.0322e-01,  ...,  7.4219e-01,\n",
            "            2.2656e-01,  7.3486e-01],\n",
            "          [ 5.8197e-02, -2.4512e-01, -7.0117e-01,  ...,  1.1650e+00,\n",
            "            3.2104e-01,  7.9639e-01],\n",
            "          ...,\n",
            "          [ 3.7598e-02,  6.1371e-02, -6.7688e-02,  ..., -2.5925e-02,\n",
            "           -4.4250e-02, -4.5657e-04],\n",
            "          [-1.9798e-03,  1.7303e-02, -1.1230e-01,  ..., -9.6436e-02,\n",
            "           -4.5990e-02,  1.1116e-02],\n",
            "          [-4.4067e-02, -4.6143e-02, -1.0309e-01,  ..., -4.2175e-02,\n",
            "           -3.6297e-03, -3.7170e-02]],\n",
            "\n",
            "         [[-2.5000e-01, -7.3730e-01,  3.5425e-01,  ...,  2.6685e-01,\n",
            "            7.0801e-01,  4.0356e-01],\n",
            "          [-2.2302e-01, -5.8691e-01,  2.4719e-01,  ...,  1.2500e-01,\n",
            "            4.2310e-01,  4.9341e-01],\n",
            "          [-6.1676e-02,  3.0347e-01, -3.5034e-01,  ..., -7.5879e-01,\n",
            "           -1.1641e+00,  1.0215e+00],\n",
            "          ...,\n",
            "          [ 2.6108e-02, -3.9276e-02, -4.8294e-03,  ..., -2.3010e-02,\n",
            "            7.8888e-03, -1.2505e-02],\n",
            "          [-1.6693e-02, -1.6937e-02,  4.6265e-02,  ..., -4.6539e-03,\n",
            "            8.8120e-03,  1.7441e-02],\n",
            "          [-2.7496e-02, -3.9276e-02,  7.4768e-02,  ..., -4.5288e-02,\n",
            "            9.2224e-02, -7.7209e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4473e+00, -2.4146e-01,  2.2583e-03,  ..., -1.4785e+00,\n",
            "            7.0953e-03, -2.4429e-02],\n",
            "          [ 8.6963e-01,  5.8350e-02,  2.8638e-01,  ..., -1.3174e+00,\n",
            "            1.1338e+00,  2.5000e-01],\n",
            "          [-4.3121e-02,  6.6699e-01,  5.6104e-01,  ..., -1.1074e+00,\n",
            "            2.3809e+00,  5.4980e-01],\n",
            "          ...,\n",
            "          [ 4.0314e-02,  3.8910e-02,  1.5381e-02,  ...,  1.7227e-02,\n",
            "            2.3911e-02,  2.6493e-03],\n",
            "          [ 8.4656e-02,  7.2815e-02,  4.0558e-02,  ...,  4.8218e-02,\n",
            "            6.2317e-02, -4.4769e-02],\n",
            "          [ 4.1687e-02,  1.2550e-03, -1.0399e-02,  ...,  3.9597e-03,\n",
            "            3.2043e-02, -2.2354e-02]],\n",
            "\n",
            "         [[ 1.9275e-01, -1.4775e+00, -7.6709e-01,  ..., -5.0635e-01,\n",
            "            4.2749e-01, -7.3389e-01],\n",
            "          [ 1.5369e-01, -7.9590e-01,  1.4087e-01,  ...,  1.6250e+00,\n",
            "            6.6455e-01, -1.6025e+00],\n",
            "          [ 4.0796e-01, -6.6846e-01, -3.4302e-01,  ..., -2.5659e-01,\n",
            "            1.2756e-01, -3.0811e-01],\n",
            "          ...,\n",
            "          [ 1.2109e-01,  1.2680e-02,  1.2360e-02,  ...,  3.7415e-02,\n",
            "            1.2164e-01,  7.5417e-03],\n",
            "          [ 7.2083e-02, -3.3295e-02, -1.0443e-01,  ...,  2.5208e-02,\n",
            "           -4.5593e-02,  1.5495e-02],\n",
            "          [ 7.0839e-03, -2.0187e-02, -1.2184e-02,  ...,  6.0333e-02,\n",
            "            7.4463e-02,  6.2866e-02]],\n",
            "\n",
            "         [[-3.8599e-01,  6.1035e-01, -3.2104e-01,  ...,  1.0974e-01,\n",
            "           -1.1953e+00, -9.7168e-01],\n",
            "          [-2.9614e-01,  5.5371e-01, -4.0259e-01,  ..., -8.4656e-02,\n",
            "           -1.0352e+00, -8.5400e-01],\n",
            "          [ 7.0679e-02,  5.3711e-02, -7.4561e-01,  ..., -9.7070e-01,\n",
            "           -1.5137e-01, -2.4536e-01],\n",
            "          ...,\n",
            "          [-2.1469e-02, -2.5955e-02, -2.3636e-02,  ..., -2.1835e-02,\n",
            "           -3.3905e-02, -4.0527e-02],\n",
            "          [ 1.0383e-04, -3.5889e-02,  4.2786e-02,  ..., -4.1779e-02,\n",
            "           -6.6895e-02, -1.3512e-02],\n",
            "          [-1.7960e-02,  1.7258e-02,  2.3300e-02,  ..., -6.9397e-02,\n",
            "           -7.0374e-02, -1.4145e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.3435e-02, -9.7070e-01,  1.8242e+00,  ...,  8.9062e-01,\n",
            "           -4.4116e-01,  7.3193e-01],\n",
            "          [ 3.3667e-01, -7.2754e-01,  3.9746e-01,  ...,  1.1582e+00,\n",
            "            7.2217e-01,  4.7388e-01],\n",
            "          [ 7.3291e-01, -6.1865e-01,  9.4629e-01,  ...,  1.0879e+00,\n",
            "            4.8145e-01,  6.8555e-01],\n",
            "          ...,\n",
            "          [-7.4036e-02, -2.3575e-02,  5.0018e-02,  ...,  9.8694e-02,\n",
            "           -5.9204e-02,  1.5674e-01],\n",
            "          [ 5.8784e-03,  2.7191e-02, -2.7786e-02,  ...,  2.9358e-02,\n",
            "           -5.4382e-02, -1.9928e-02],\n",
            "          [-4.9286e-02,  5.5084e-02,  9.5764e-02,  ...,  6.6071e-03,\n",
            "            4.2908e-02, -8.8577e-03]],\n",
            "\n",
            "         [[-5.2734e-01, -1.5039e+00,  1.6250e+00,  ..., -5.0049e-01,\n",
            "            1.7900e+00, -9.5459e-01],\n",
            "          [ 1.1749e-01, -1.1543e+00,  1.2236e+00,  ..., -6.9287e-01,\n",
            "           -4.0088e-01, -3.2690e-01],\n",
            "          [-2.5415e-01, -1.3223e+00,  1.4473e+00,  ..., -5.2979e-01,\n",
            "            9.5117e-01, -7.0801e-01],\n",
            "          ...,\n",
            "          [ 8.8043e-03, -1.0431e-01,  2.9739e-02,  ..., -2.5818e-02,\n",
            "           -6.3705e-03, -6.1157e-02],\n",
            "          [-5.9143e-02, -3.3325e-02,  9.4910e-03,  ..., -4.6478e-02,\n",
            "            1.1032e-02, -7.3914e-02],\n",
            "          [-4.4189e-02, -5.8258e-02,  3.1647e-02,  ..., -5.7098e-02,\n",
            "            8.2703e-02, -3.9581e-02]],\n",
            "\n",
            "         [[-6.5674e-01,  4.7412e-01,  1.8494e-01,  ..., -5.9473e-01,\n",
            "            3.5498e-01,  9.1895e-01],\n",
            "          [-4.6338e-01, -8.2825e-02,  1.5063e-01,  ..., -5.2490e-01,\n",
            "            7.5928e-01,  8.6670e-01],\n",
            "          [ 3.0176e-01, -9.7412e-01, -1.2683e-01,  ..., -4.3652e-01,\n",
            "            1.4463e+00,  9.1211e-01],\n",
            "          ...,\n",
            "          [-3.7750e-02, -5.4199e-02, -5.8960e-02,  ..., -8.0948e-03,\n",
            "            7.0007e-02,  5.8746e-02],\n",
            "          [ 2.6382e-02, -5.5603e-02, -6.2500e-02,  ..., -9.8328e-02,\n",
            "            2.0142e-02, -2.2354e-02],\n",
            "          [-9.3994e-03, -3.0304e-02, -5.4047e-02,  ..., -3.8696e-02,\n",
            "            5.5969e-02,  1.1406e-02]]]], device='cuda:0', dtype=torch.float16)\n",
            "tensor([[[[-1.6289e+00,  1.3203e+00,  1.5352e+00,  ..., -3.1270e+00,\n",
            "           -2.8789e+00, -2.0264e-01],\n",
            "          [-1.4160e-01, -7.3486e-02, -4.2310e-01,  ..., -2.2693e-01,\n",
            "            2.3157e-01,  1.3457e+00],\n",
            "          [-8.3691e-01,  6.8262e-01,  7.5732e-01,  ..., -1.7197e+00,\n",
            "           -1.0166e+00,  3.6255e-01],\n",
            "          ...,\n",
            "          [ 6.5956e-03,  2.5620e-02,  1.0150e-01,  ..., -6.6805e-04,\n",
            "           -6.3904e-02,  5.0171e-02],\n",
            "          [-9.5459e-02, -4.0558e-02, -4.1466e-03,  ..., -2.6733e-02,\n",
            "           -7.2083e-02,  4.0985e-02],\n",
            "          [-3.7270e-03, -3.8361e-02,  9.7229e-02,  ..., -5.6580e-02,\n",
            "           -1.1365e-01, -1.3214e-02]],\n",
            "\n",
            "         [[ 2.0462e-02, -1.5664e+00, -9.5020e-01,  ..., -3.1421e-01,\n",
            "           -3.7378e-01,  1.3809e+00],\n",
            "          [ 6.0742e-01, -5.7031e-01, -8.9404e-01,  ...,  2.7539e-01,\n",
            "           -6.0498e-01,  2.1436e-01],\n",
            "          [ 3.5248e-02,  3.1616e-01,  3.5986e-01,  ...,  5.8057e-01,\n",
            "           -1.0029e+00, -8.9062e-01],\n",
            "          ...,\n",
            "          [ 5.3284e-02, -3.6865e-02,  6.1188e-02,  ..., -4.0955e-02,\n",
            "           -3.2104e-02,  5.8502e-02],\n",
            "          [ 1.3123e-01, -3.9001e-02,  4.6906e-02,  ...,  2.5024e-02,\n",
            "           -4.1443e-02,  3.8330e-02],\n",
            "          [ 5.9235e-02, -8.3984e-02,  4.0405e-02,  ...,  6.1226e-03,\n",
            "           -7.9041e-02, -1.6129e-02]],\n",
            "\n",
            "         [[-1.1182e+00,  1.1924e+00,  6.0791e-01,  ...,  2.2339e-01,\n",
            "           -4.9194e-01,  1.1270e+00],\n",
            "          [-3.6914e-01, -8.1104e-01, -2.0154e-01,  ..., -7.6221e-01,\n",
            "            1.2549e+00,  9.5068e-01],\n",
            "          [-3.1787e-01, -1.2080e+00, -2.1960e-01,  ..., -1.0332e+00,\n",
            "            1.5908e+00,  5.7520e-01],\n",
            "          ...,\n",
            "          [-2.8091e-02,  1.3817e-02, -2.7634e-02,  ..., -2.2842e-02,\n",
            "           -2.8198e-02,  3.7880e-03],\n",
            "          [-2.4673e-02,  7.9285e-02, -2.5314e-02,  ..., -1.0277e-02,\n",
            "            5.3101e-02, -9.7473e-02],\n",
            "          [-7.3395e-03, -2.3407e-02,  3.4271e-02,  ..., -1.1131e-02,\n",
            "            6.9885e-02, -4.6356e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7207e-01, -4.9219e-01, -1.1465e+00,  ..., -5.3662e-01,\n",
            "           -4.0283e-01,  3.0615e-01],\n",
            "          [ 2.4927e-01, -3.5645e-01, -9.8047e-01,  ..., -5.0684e-01,\n",
            "           -2.2107e-01,  1.7419e-01],\n",
            "          [-2.4506e-02, -1.4600e-01, -6.7920e-01,  ..., -3.5327e-01,\n",
            "           -7.9285e-02,  1.2219e-01],\n",
            "          ...,\n",
            "          [ 1.2390e-02, -4.0009e-02, -1.0345e-02,  ..., -1.4084e-02,\n",
            "           -3.0624e-02,  5.1117e-02],\n",
            "          [ 3.6713e-02, -1.0248e-01, -3.4058e-02,  ..., -5.2368e-02,\n",
            "           -1.2891e-01,  1.1200e-01],\n",
            "          [ 4.1748e-02, -2.6627e-02, -6.0638e-02,  ...,  3.0930e-02,\n",
            "           -1.1005e-01,  1.3098e-01]],\n",
            "\n",
            "         [[-1.1006e+00, -4.6997e-01,  1.0029e+00,  ...,  4.0991e-01,\n",
            "            1.9824e-01,  6.3867e-01],\n",
            "          [-6.2451e-01, -3.3325e-01,  3.0322e-01,  ...,  7.4219e-01,\n",
            "            2.2656e-01,  7.3486e-01],\n",
            "          [ 5.8197e-02, -2.4512e-01, -7.0117e-01,  ...,  1.1650e+00,\n",
            "            3.2104e-01,  7.9639e-01],\n",
            "          ...,\n",
            "          [ 3.7598e-02,  6.1371e-02, -6.7688e-02,  ..., -2.5940e-02,\n",
            "           -4.4250e-02, -4.4847e-04],\n",
            "          [-1.9760e-03,  1.7303e-02, -1.1230e-01,  ..., -9.6436e-02,\n",
            "           -4.5990e-02,  1.1116e-02],\n",
            "          [-4.4067e-02, -4.6143e-02, -1.0309e-01,  ..., -4.2175e-02,\n",
            "           -3.6335e-03, -3.7170e-02]],\n",
            "\n",
            "         [[-2.5000e-01, -7.3730e-01,  3.5425e-01,  ...,  2.6685e-01,\n",
            "            7.0801e-01,  4.0356e-01],\n",
            "          [-2.2302e-01, -5.8691e-01,  2.4719e-01,  ...,  1.2500e-01,\n",
            "            4.2310e-01,  4.9341e-01],\n",
            "          [-6.1676e-02,  3.0347e-01, -3.5034e-01,  ..., -7.5879e-01,\n",
            "           -1.1641e+00,  1.0215e+00],\n",
            "          ...,\n",
            "          [ 2.6123e-02, -3.9307e-02, -4.8180e-03,  ..., -2.3010e-02,\n",
            "            7.8735e-03, -1.2512e-02],\n",
            "          [-1.6678e-02, -1.6937e-02,  4.6265e-02,  ..., -4.6501e-03,\n",
            "            8.7891e-03,  1.7441e-02],\n",
            "          [-2.7496e-02, -3.9276e-02,  7.4768e-02,  ..., -4.5288e-02,\n",
            "            9.2163e-02, -7.7209e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4473e+00, -2.4146e-01,  2.2583e-03,  ..., -1.4785e+00,\n",
            "            7.0953e-03, -2.4429e-02],\n",
            "          [ 8.6963e-01,  5.8350e-02,  2.8638e-01,  ..., -1.3174e+00,\n",
            "            1.1338e+00,  2.5000e-01],\n",
            "          [-4.3121e-02,  6.6699e-01,  5.6104e-01,  ..., -1.1074e+00,\n",
            "            2.3809e+00,  5.4980e-01],\n",
            "          ...,\n",
            "          [ 4.0314e-02,  3.8910e-02,  1.5411e-02,  ...,  1.7227e-02,\n",
            "            2.3911e-02,  2.6550e-03],\n",
            "          [ 8.4656e-02,  7.2815e-02,  4.0558e-02,  ...,  4.8187e-02,\n",
            "            6.2317e-02, -4.4769e-02],\n",
            "          [ 4.1687e-02,  1.2693e-03, -1.0384e-02,  ...,  3.9558e-03,\n",
            "            3.2043e-02, -2.2354e-02]],\n",
            "\n",
            "         [[ 1.9275e-01, -1.4775e+00, -7.6709e-01,  ..., -5.0635e-01,\n",
            "            4.2749e-01, -7.3389e-01],\n",
            "          [ 1.5369e-01, -7.9590e-01,  1.4087e-01,  ...,  1.6250e+00,\n",
            "            6.6455e-01, -1.6025e+00],\n",
            "          [ 4.0796e-01, -6.6846e-01, -3.4302e-01,  ..., -2.5659e-01,\n",
            "            1.2756e-01, -3.0811e-01],\n",
            "          ...,\n",
            "          [ 1.2109e-01,  1.2688e-02,  1.2360e-02,  ...,  3.7415e-02,\n",
            "            1.2164e-01,  7.5455e-03],\n",
            "          [ 7.2083e-02, -3.3295e-02, -1.0443e-01,  ...,  2.5208e-02,\n",
            "           -4.5593e-02,  1.5480e-02],\n",
            "          [ 7.0953e-03, -2.0187e-02, -1.2169e-02,  ...,  6.0333e-02,\n",
            "            7.4463e-02,  6.2866e-02]],\n",
            "\n",
            "         [[-3.8599e-01,  6.1035e-01, -3.2104e-01,  ...,  1.0974e-01,\n",
            "           -1.1953e+00, -9.7168e-01],\n",
            "          [-2.9614e-01,  5.5371e-01, -4.0259e-01,  ..., -8.4656e-02,\n",
            "           -1.0352e+00, -8.5400e-01],\n",
            "          [ 7.0679e-02,  5.3711e-02, -7.4561e-01,  ..., -9.7070e-01,\n",
            "           -1.5137e-01, -2.4536e-01],\n",
            "          ...,\n",
            "          [-2.1469e-02, -2.5970e-02, -2.3621e-02,  ..., -2.1835e-02,\n",
            "           -3.3905e-02, -4.0527e-02],\n",
            "          [ 9.8109e-05, -3.5889e-02,  4.2755e-02,  ..., -4.1809e-02,\n",
            "           -6.6895e-02, -1.3519e-02],\n",
            "          [-1.7944e-02,  1.7258e-02,  2.3300e-02,  ..., -6.9397e-02,\n",
            "           -7.0374e-02, -1.4137e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.3435e-02, -9.7070e-01,  1.8242e+00,  ...,  8.9062e-01,\n",
            "           -4.4116e-01,  7.3193e-01],\n",
            "          [ 3.3667e-01, -7.2754e-01,  3.9746e-01,  ...,  1.1582e+00,\n",
            "            7.2217e-01,  4.7388e-01],\n",
            "          [ 7.3291e-01, -6.1865e-01,  9.4629e-01,  ...,  1.0879e+00,\n",
            "            4.8145e-01,  6.8555e-01],\n",
            "          ...,\n",
            "          [-7.3975e-02, -2.3590e-02,  5.0018e-02,  ...,  9.8694e-02,\n",
            "           -5.9204e-02,  1.5674e-01],\n",
            "          [ 5.8746e-03,  2.7176e-02, -2.7771e-02,  ...,  2.9373e-02,\n",
            "           -5.4382e-02, -1.9897e-02],\n",
            "          [-4.9316e-02,  5.5084e-02,  9.5764e-02,  ...,  6.5956e-03,\n",
            "            4.2908e-02, -8.8348e-03]],\n",
            "\n",
            "         [[-5.2734e-01, -1.5039e+00,  1.6250e+00,  ..., -5.0049e-01,\n",
            "            1.7900e+00, -9.5459e-01],\n",
            "          [ 1.1749e-01, -1.1543e+00,  1.2236e+00,  ..., -6.9287e-01,\n",
            "           -4.0088e-01, -3.2690e-01],\n",
            "          [-2.5415e-01, -1.3223e+00,  1.4473e+00,  ..., -5.2979e-01,\n",
            "            9.5117e-01, -7.0801e-01],\n",
            "          ...,\n",
            "          [ 8.8043e-03, -1.0431e-01,  2.9724e-02,  ..., -2.5818e-02,\n",
            "           -6.3515e-03, -6.1157e-02],\n",
            "          [-5.9143e-02, -3.3295e-02,  9.4910e-03,  ..., -4.6478e-02,\n",
            "            1.1047e-02, -7.3853e-02],\n",
            "          [-4.4189e-02, -5.8258e-02,  3.1616e-02,  ..., -5.7098e-02,\n",
            "            8.2703e-02, -3.9581e-02]],\n",
            "\n",
            "         [[-6.5674e-01,  4.7412e-01,  1.8494e-01,  ..., -5.9473e-01,\n",
            "            3.5498e-01,  9.1895e-01],\n",
            "          [-4.6338e-01, -8.2825e-02,  1.5063e-01,  ..., -5.2490e-01,\n",
            "            7.5928e-01,  8.6670e-01],\n",
            "          [ 3.0176e-01, -9.7412e-01, -1.2683e-01,  ..., -4.3652e-01,\n",
            "            1.4463e+00,  9.1211e-01],\n",
            "          ...,\n",
            "          [-3.7781e-02, -5.4199e-02, -5.8990e-02,  ..., -8.1100e-03,\n",
            "            7.0007e-02,  5.8716e-02],\n",
            "          [ 2.6382e-02, -5.5603e-02, -6.2500e-02,  ..., -9.8328e-02,\n",
            "            2.0157e-02, -2.2339e-02],\n",
            "          [-9.3994e-03, -3.0289e-02, -5.4077e-02,  ..., -3.8696e-02,\n",
            "            5.5969e-02,  1.1414e-02]]]], device='cuda:0', dtype=torch.float16)\n",
            "The maximum difference between torch and triton is 0.0009765625\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46801560",
        "outputId": "839e2a1e-7aa0-4081-b0d7-59ea8721966d"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Ensure we are in the correct directory for relative imports\n",
        "current_dir = os.getcwd()\n",
        "expected_dir = '/content/drive/MyDrive/Flash-Kernels'\n",
        "\n",
        "if current_dir != expected_dir:\n",
        "    %cd {expected_dir}\n",
        "\n",
        "# Add the directory containing the module to the Python path if it's not already there\n",
        "module_path = './04_flash_attention'\n",
        "if module_path not in sys.path:\n",
        "    sys.path.insert(0, module_path)\n",
        "\n",
        "# Now import the functions\n",
        "from triton_flash_attn import flash_attn_forward\n",
        "\n",
        "print(\"Successfully imported flash_attn_forward.\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-1.6289e+00,  1.3203e+00,  1.5352e+00,  ..., -3.1270e+00,\n",
            "           -2.8789e+00, -2.0264e-01],\n",
            "          [-1.4160e-01, -7.3486e-02, -4.2310e-01,  ..., -2.2693e-01,\n",
            "            2.3157e-01,  1.3457e+00],\n",
            "          [-8.3691e-01,  6.8262e-01,  7.5732e-01,  ..., -1.7197e+00,\n",
            "           -1.0166e+00,  3.6255e-01],\n",
            "          ...,\n",
            "          [ 6.5880e-03,  2.5620e-02,  1.0150e-01,  ..., -6.5660e-04,\n",
            "           -6.3904e-02,  5.0171e-02],\n",
            "          [-9.5459e-02, -4.0588e-02, -4.1466e-03,  ..., -2.6718e-02,\n",
            "           -7.2083e-02,  4.0985e-02],\n",
            "          [-3.7384e-03, -3.8391e-02,  9.7168e-02,  ..., -5.6580e-02,\n",
            "           -1.1359e-01, -1.3229e-02]],\n",
            "\n",
            "         [[ 2.0462e-02, -1.5664e+00, -9.5020e-01,  ..., -3.1421e-01,\n",
            "           -3.7378e-01,  1.3809e+00],\n",
            "          [ 6.0742e-01, -5.7031e-01, -8.9404e-01,  ...,  2.7539e-01,\n",
            "           -6.0498e-01,  2.1436e-01],\n",
            "          [ 3.5248e-02,  3.1616e-01,  3.5986e-01,  ...,  5.8057e-01,\n",
            "           -1.0029e+00, -8.9062e-01],\n",
            "          ...,\n",
            "          [ 5.3284e-02, -3.6865e-02,  6.1188e-02,  ..., -4.0924e-02,\n",
            "           -3.2104e-02,  5.8502e-02],\n",
            "          [ 1.3123e-01, -3.8971e-02,  4.6875e-02,  ...,  2.5024e-02,\n",
            "           -4.1443e-02,  3.8330e-02],\n",
            "          [ 5.9235e-02, -8.3984e-02,  4.0405e-02,  ...,  6.1264e-03,\n",
            "           -7.9041e-02, -1.6113e-02]],\n",
            "\n",
            "         [[-1.1182e+00,  1.1924e+00,  6.0791e-01,  ...,  2.2339e-01,\n",
            "           -4.9194e-01,  1.1270e+00],\n",
            "          [-3.6914e-01, -8.1104e-01, -2.0154e-01,  ..., -7.6221e-01,\n",
            "            1.2549e+00,  9.5068e-01],\n",
            "          [-3.1787e-01, -1.2080e+00, -2.1960e-01,  ..., -1.0332e+00,\n",
            "            1.5908e+00,  5.7520e-01],\n",
            "          ...,\n",
            "          [-2.8091e-02,  1.3809e-02, -2.7603e-02,  ..., -2.2842e-02,\n",
            "           -2.8183e-02,  3.7956e-03],\n",
            "          [-2.4673e-02,  7.9285e-02, -2.5314e-02,  ..., -1.0284e-02,\n",
            "            5.3040e-02, -9.7473e-02],\n",
            "          [-7.3318e-03, -2.3407e-02,  3.4271e-02,  ..., -1.1108e-02,\n",
            "            6.9885e-02, -4.6356e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7207e-01, -4.9219e-01, -1.1465e+00,  ..., -5.3662e-01,\n",
            "           -4.0283e-01,  3.0615e-01],\n",
            "          [ 2.4927e-01, -3.5645e-01, -9.8047e-01,  ..., -5.0684e-01,\n",
            "           -2.2107e-01,  1.7419e-01],\n",
            "          [-2.4506e-02, -1.4600e-01, -6.7920e-01,  ..., -3.5327e-01,\n",
            "           -7.9285e-02,  1.2219e-01],\n",
            "          ...,\n",
            "          [ 1.2390e-02, -4.0009e-02, -1.0345e-02,  ..., -1.4084e-02,\n",
            "           -3.0640e-02,  5.1147e-02],\n",
            "          [ 3.6743e-02, -1.0242e-01, -3.4058e-02,  ..., -5.2399e-02,\n",
            "           -1.2891e-01,  1.1200e-01],\n",
            "          [ 4.1748e-02, -2.6611e-02, -6.0669e-02,  ...,  3.0960e-02,\n",
            "           -1.1005e-01,  1.3098e-01]],\n",
            "\n",
            "         [[-1.1006e+00, -4.6997e-01,  1.0029e+00,  ...,  4.0991e-01,\n",
            "            1.9824e-01,  6.3867e-01],\n",
            "          [-6.2451e-01, -3.3325e-01,  3.0322e-01,  ...,  7.4219e-01,\n",
            "            2.2656e-01,  7.3486e-01],\n",
            "          [ 5.8197e-02, -2.4512e-01, -7.0117e-01,  ...,  1.1650e+00,\n",
            "            3.2104e-01,  7.9639e-01],\n",
            "          ...,\n",
            "          [ 3.7598e-02,  6.1371e-02, -6.7688e-02,  ..., -2.5925e-02,\n",
            "           -4.4250e-02, -4.5657e-04],\n",
            "          [-1.9798e-03,  1.7303e-02, -1.1230e-01,  ..., -9.6436e-02,\n",
            "           -4.5990e-02,  1.1116e-02],\n",
            "          [-4.4067e-02, -4.6143e-02, -1.0309e-01,  ..., -4.2175e-02,\n",
            "           -3.6297e-03, -3.7170e-02]],\n",
            "\n",
            "         [[-2.5000e-01, -7.3730e-01,  3.5425e-01,  ...,  2.6685e-01,\n",
            "            7.0801e-01,  4.0356e-01],\n",
            "          [-2.2302e-01, -5.8691e-01,  2.4719e-01,  ...,  1.2500e-01,\n",
            "            4.2310e-01,  4.9341e-01],\n",
            "          [-6.1676e-02,  3.0347e-01, -3.5034e-01,  ..., -7.5879e-01,\n",
            "           -1.1641e+00,  1.0215e+00],\n",
            "          ...,\n",
            "          [ 2.6108e-02, -3.9276e-02, -4.8294e-03,  ..., -2.3010e-02,\n",
            "            7.8888e-03, -1.2505e-02],\n",
            "          [-1.6693e-02, -1.6937e-02,  4.6265e-02,  ..., -4.6539e-03,\n",
            "            8.8120e-03,  1.7441e-02],\n",
            "          [-2.7496e-02, -3.9276e-02,  7.4768e-02,  ..., -4.5288e-02,\n",
            "            9.2224e-02, -7.7209e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4473e+00, -2.4146e-01,  2.2583e-03,  ..., -1.4785e+00,\n",
            "            7.0953e-03, -2.4429e-02],\n",
            "          [ 8.6963e-01,  5.8350e-02,  2.8638e-01,  ..., -1.3174e+00,\n",
            "            1.1338e+00,  2.5000e-01],\n",
            "          [-4.3121e-02,  6.6699e-01,  5.6104e-01,  ..., -1.1074e+00,\n",
            "            2.3809e+00,  5.4980e-01],\n",
            "          ...,\n",
            "          [ 4.0314e-02,  3.8910e-02,  1.5381e-02,  ...,  1.7227e-02,\n",
            "            2.3911e-02,  2.6493e-03],\n",
            "          [ 8.4656e-02,  7.2815e-02,  4.0558e-02,  ...,  4.8218e-02,\n",
            "            6.2317e-02, -4.4769e-02],\n",
            "          [ 4.1687e-02,  1.2550e-03, -1.0399e-02,  ...,  3.9597e-03,\n",
            "            3.2043e-02, -2.2354e-02]],\n",
            "\n",
            "         [[ 1.9275e-01, -1.4775e+00, -7.6709e-01,  ..., -5.0635e-01,\n",
            "            4.2749e-01, -7.3389e-01],\n",
            "          [ 1.5369e-01, -7.9590e-01,  1.4087e-01,  ...,  1.6250e+00,\n",
            "            6.6455e-01, -1.6025e+00],\n",
            "          [ 4.0796e-01, -6.6846e-01, -3.4302e-01,  ..., -2.5659e-01,\n",
            "            1.2756e-01, -3.0811e-01],\n",
            "          ...,\n",
            "          [ 1.2109e-01,  1.2680e-02,  1.2360e-02,  ...,  3.7415e-02,\n",
            "            1.2164e-01,  7.5417e-03],\n",
            "          [ 7.2083e-02, -3.3295e-02, -1.0443e-01,  ...,  2.5208e-02,\n",
            "           -4.5593e-02,  1.5495e-02],\n",
            "          [ 7.0839e-03, -2.0187e-02, -1.2184e-02,  ...,  6.0333e-02,\n",
            "            7.4463e-02,  6.2866e-02]],\n",
            "\n",
            "         [[-3.8599e-01,  6.1035e-01, -3.2104e-01,  ...,  1.0974e-01,\n",
            "           -1.1953e+00, -9.7168e-01],\n",
            "          [-2.9614e-01,  5.5371e-01, -4.0259e-01,  ..., -8.4656e-02,\n",
            "           -1.0352e+00, -8.5400e-01],\n",
            "          [ 7.0679e-02,  5.3711e-02, -7.4561e-01,  ..., -9.7070e-01,\n",
            "           -1.5137e-01, -2.4536e-01],\n",
            "          ...,\n",
            "          [-2.1469e-02, -2.5955e-02, -2.3636e-02,  ..., -2.1835e-02,\n",
            "           -3.3905e-02, -4.0527e-02],\n",
            "          [ 1.0383e-04, -3.5889e-02,  4.2786e-02,  ..., -4.1779e-02,\n",
            "           -6.6895e-02, -1.3512e-02],\n",
            "          [-1.7960e-02,  1.7258e-02,  2.3300e-02,  ..., -6.9397e-02,\n",
            "           -7.0374e-02, -1.4145e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.3435e-02, -9.7070e-01,  1.8242e+00,  ...,  8.9062e-01,\n",
            "           -4.4116e-01,  7.3193e-01],\n",
            "          [ 3.3667e-01, -7.2754e-01,  3.9746e-01,  ...,  1.1582e+00,\n",
            "            7.2217e-01,  4.7388e-01],\n",
            "          [ 7.3291e-01, -6.1865e-01,  9.4629e-01,  ...,  1.0879e+00,\n",
            "            4.8145e-01,  6.8555e-01],\n",
            "          ...,\n",
            "          [-7.4036e-02, -2.3575e-02,  5.0018e-02,  ...,  9.8694e-02,\n",
            "           -5.9204e-02,  1.5674e-01],\n",
            "          [ 5.8784e-03,  2.7191e-02, -2.7786e-02,  ...,  2.9358e-02,\n",
            "           -5.4382e-02, -1.9928e-02],\n",
            "          [-4.9286e-02,  5.5084e-02,  9.5764e-02,  ...,  6.6071e-03,\n",
            "            4.2908e-02, -8.8577e-03]],\n",
            "\n",
            "         [[-5.2734e-01, -1.5039e+00,  1.6250e+00,  ..., -5.0049e-01,\n",
            "            1.7900e+00, -9.5459e-01],\n",
            "          [ 1.1749e-01, -1.1543e+00,  1.2236e+00,  ..., -6.9287e-01,\n",
            "           -4.0088e-01, -3.2690e-01],\n",
            "          [-2.5415e-01, -1.3223e+00,  1.4473e+00,  ..., -5.2979e-01,\n",
            "            9.5117e-01, -7.0801e-01],\n",
            "          ...,\n",
            "          [ 8.8043e-03, -1.0431e-01,  2.9739e-02,  ..., -2.5818e-02,\n",
            "           -6.3705e-03, -6.1157e-02],\n",
            "          [-5.9143e-02, -3.3325e-02,  9.4910e-03,  ..., -4.6478e-02,\n",
            "            1.1032e-02, -7.3914e-02],\n",
            "          [-4.4189e-02, -5.8258e-02,  3.1647e-02,  ..., -5.7098e-02,\n",
            "            8.2703e-02, -3.9581e-02]],\n",
            "\n",
            "         [[-6.5674e-01,  4.7412e-01,  1.8494e-01,  ..., -5.9473e-01,\n",
            "            3.5498e-01,  9.1895e-01],\n",
            "          [-4.6338e-01, -8.2825e-02,  1.5063e-01,  ..., -5.2490e-01,\n",
            "            7.5928e-01,  8.6670e-01],\n",
            "          [ 3.0176e-01, -9.7412e-01, -1.2683e-01,  ..., -4.3652e-01,\n",
            "            1.4463e+00,  9.1211e-01],\n",
            "          ...,\n",
            "          [-3.7750e-02, -5.4199e-02, -5.8960e-02,  ..., -8.0948e-03,\n",
            "            7.0007e-02,  5.8746e-02],\n",
            "          [ 2.6382e-02, -5.5603e-02, -6.2500e-02,  ..., -9.8328e-02,\n",
            "            2.0142e-02, -2.2354e-02],\n",
            "          [-9.3994e-03, -3.0304e-02, -5.4047e-02,  ..., -3.8696e-02,\n",
            "            5.5969e-02,  1.1406e-02]]]], device='cuda:0', dtype=torch.float16)\n",
            "tensor([[[[-1.6289e+00,  1.3203e+00,  1.5352e+00,  ..., -3.1270e+00,\n",
            "           -2.8789e+00, -2.0264e-01],\n",
            "          [-1.4160e-01, -7.3486e-02, -4.2310e-01,  ..., -2.2693e-01,\n",
            "            2.3157e-01,  1.3457e+00],\n",
            "          [-8.3691e-01,  6.8262e-01,  7.5732e-01,  ..., -1.7197e+00,\n",
            "           -1.0166e+00,  3.6255e-01],\n",
            "          ...,\n",
            "          [ 6.5956e-03,  2.5620e-02,  1.0150e-01,  ..., -6.6805e-04,\n",
            "           -6.3904e-02,  5.0171e-02],\n",
            "          [-9.5459e-02, -4.0558e-02, -4.1466e-03,  ..., -2.6733e-02,\n",
            "           -7.2083e-02,  4.0985e-02],\n",
            "          [-3.7270e-03, -3.8361e-02,  9.7229e-02,  ..., -5.6580e-02,\n",
            "           -1.1365e-01, -1.3214e-02]],\n",
            "\n",
            "         [[ 2.0462e-02, -1.5664e+00, -9.5020e-01,  ..., -3.1421e-01,\n",
            "           -3.7378e-01,  1.3809e+00],\n",
            "          [ 6.0742e-01, -5.7031e-01, -8.9404e-01,  ...,  2.7539e-01,\n",
            "           -6.0498e-01,  2.1436e-01],\n",
            "          [ 3.5248e-02,  3.1616e-01,  3.5986e-01,  ...,  5.8057e-01,\n",
            "           -1.0029e+00, -8.9062e-01],\n",
            "          ...,\n",
            "          [ 5.3284e-02, -3.6865e-02,  6.1188e-02,  ..., -4.0955e-02,\n",
            "           -3.2104e-02,  5.8502e-02],\n",
            "          [ 1.3123e-01, -3.9001e-02,  4.6906e-02,  ...,  2.5024e-02,\n",
            "           -4.1443e-02,  3.8330e-02],\n",
            "          [ 5.9235e-02, -8.3984e-02,  4.0405e-02,  ...,  6.1226e-03,\n",
            "           -7.9041e-02, -1.6129e-02]],\n",
            "\n",
            "         [[-1.1182e+00,  1.1924e+00,  6.0791e-01,  ...,  2.2339e-01,\n",
            "           -4.9194e-01,  1.1270e+00],\n",
            "          [-3.6914e-01, -8.1104e-01, -2.0154e-01,  ..., -7.6221e-01,\n",
            "            1.2549e+00,  9.5068e-01],\n",
            "          [-3.1787e-01, -1.2080e+00, -2.1960e-01,  ..., -1.0332e+00,\n",
            "            1.5908e+00,  5.7520e-01],\n",
            "          ...,\n",
            "          [-2.8091e-02,  1.3817e-02, -2.7634e-02,  ..., -2.2842e-02,\n",
            "           -2.8198e-02,  3.7880e-03],\n",
            "          [-2.4673e-02,  7.9285e-02, -2.5314e-02,  ..., -1.0277e-02,\n",
            "            5.3101e-02, -9.7473e-02],\n",
            "          [-7.3395e-03, -2.3407e-02,  3.4271e-02,  ..., -1.1131e-02,\n",
            "            6.9885e-02, -4.6356e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7207e-01, -4.9219e-01, -1.1465e+00,  ..., -5.3662e-01,\n",
            "           -4.0283e-01,  3.0615e-01],\n",
            "          [ 2.4927e-01, -3.5645e-01, -9.8047e-01,  ..., -5.0684e-01,\n",
            "           -2.2107e-01,  1.7419e-01],\n",
            "          [-2.4506e-02, -1.4600e-01, -6.7920e-01,  ..., -3.5327e-01,\n",
            "           -7.9285e-02,  1.2219e-01],\n",
            "          ...,\n",
            "          [ 1.2390e-02, -4.0009e-02, -1.0345e-02,  ..., -1.4084e-02,\n",
            "           -3.0624e-02,  5.1117e-02],\n",
            "          [ 3.6713e-02, -1.0248e-01, -3.4058e-02,  ..., -5.2368e-02,\n",
            "           -1.2891e-01,  1.1200e-01],\n",
            "          [ 4.1748e-02, -2.6627e-02, -6.0638e-02,  ...,  3.0930e-02,\n",
            "           -1.1005e-01,  1.3098e-01]],\n",
            "\n",
            "         [[-1.1006e+00, -4.6997e-01,  1.0029e+00,  ...,  4.0991e-01,\n",
            "            1.9824e-01,  6.3867e-01],\n",
            "          [-6.2451e-01, -3.3325e-01,  3.0322e-01,  ...,  7.4219e-01,\n",
            "            2.2656e-01,  7.3486e-01],\n",
            "          [ 5.8197e-02, -2.4512e-01, -7.0117e-01,  ...,  1.1650e+00,\n",
            "            3.2104e-01,  7.9639e-01],\n",
            "          ...,\n",
            "          [ 3.7598e-02,  6.1371e-02, -6.7688e-02,  ..., -2.5940e-02,\n",
            "           -4.4250e-02, -4.4847e-04],\n",
            "          [-1.9760e-03,  1.7303e-02, -1.1230e-01,  ..., -9.6436e-02,\n",
            "           -4.5990e-02,  1.1116e-02],\n",
            "          [-4.4067e-02, -4.6143e-02, -1.0309e-01,  ..., -4.2175e-02,\n",
            "           -3.6335e-03, -3.7170e-02]],\n",
            "\n",
            "         [[-2.5000e-01, -7.3730e-01,  3.5425e-01,  ...,  2.6685e-01,\n",
            "            7.0801e-01,  4.0356e-01],\n",
            "          [-2.2302e-01, -5.8691e-01,  2.4719e-01,  ...,  1.2500e-01,\n",
            "            4.2310e-01,  4.9341e-01],\n",
            "          [-6.1676e-02,  3.0347e-01, -3.5034e-01,  ..., -7.5879e-01,\n",
            "           -1.1641e+00,  1.0215e+00],\n",
            "          ...,\n",
            "          [ 2.6123e-02, -3.9307e-02, -4.8180e-03,  ..., -2.3010e-02,\n",
            "            7.8735e-03, -1.2512e-02],\n",
            "          [-1.6678e-02, -1.6937e-02,  4.6265e-02,  ..., -4.6501e-03,\n",
            "            8.7891e-03,  1.7441e-02],\n",
            "          [-2.7496e-02, -3.9276e-02,  7.4768e-02,  ..., -4.5288e-02,\n",
            "            9.2163e-02, -7.7209e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4473e+00, -2.4146e-01,  2.2583e-03,  ..., -1.4785e+00,\n",
            "            7.0953e-03, -2.4429e-02],\n",
            "          [ 8.6963e-01,  5.8350e-02,  2.8638e-01,  ..., -1.3174e+00,\n",
            "            1.1338e+00,  2.5000e-01],\n",
            "          [-4.3121e-02,  6.6699e-01,  5.6104e-01,  ..., -1.1074e+00,\n",
            "            2.3809e+00,  5.4980e-01],\n",
            "          ...,\n",
            "          [ 4.0314e-02,  3.8910e-02,  1.5411e-02,  ...,  1.7227e-02,\n",
            "            2.3911e-02,  2.6550e-03],\n",
            "          [ 8.4656e-02,  7.2815e-02,  4.0558e-02,  ...,  4.8187e-02,\n",
            "            6.2317e-02, -4.4769e-02],\n",
            "          [ 4.1687e-02,  1.2693e-03, -1.0384e-02,  ...,  3.9558e-03,\n",
            "            3.2043e-02, -2.2354e-02]],\n",
            "\n",
            "         [[ 1.9275e-01, -1.4775e+00, -7.6709e-01,  ..., -5.0635e-01,\n",
            "            4.2749e-01, -7.3389e-01],\n",
            "          [ 1.5369e-01, -7.9590e-01,  1.4087e-01,  ...,  1.6250e+00,\n",
            "            6.6455e-01, -1.6025e+00],\n",
            "          [ 4.0796e-01, -6.6846e-01, -3.4302e-01,  ..., -2.5659e-01,\n",
            "            1.2756e-01, -3.0811e-01],\n",
            "          ...,\n",
            "          [ 1.2109e-01,  1.2688e-02,  1.2360e-02,  ...,  3.7415e-02,\n",
            "            1.2164e-01,  7.5455e-03],\n",
            "          [ 7.2083e-02, -3.3295e-02, -1.0443e-01,  ...,  2.5208e-02,\n",
            "           -4.5593e-02,  1.5480e-02],\n",
            "          [ 7.0953e-03, -2.0187e-02, -1.2169e-02,  ...,  6.0333e-02,\n",
            "            7.4463e-02,  6.2866e-02]],\n",
            "\n",
            "         [[-3.8599e-01,  6.1035e-01, -3.2104e-01,  ...,  1.0974e-01,\n",
            "           -1.1953e+00, -9.7168e-01],\n",
            "          [-2.9614e-01,  5.5371e-01, -4.0259e-01,  ..., -8.4656e-02,\n",
            "           -1.0352e+00, -8.5400e-01],\n",
            "          [ 7.0679e-02,  5.3711e-02, -7.4561e-01,  ..., -9.7070e-01,\n",
            "           -1.5137e-01, -2.4536e-01],\n",
            "          ...,\n",
            "          [-2.1469e-02, -2.5970e-02, -2.3621e-02,  ..., -2.1835e-02,\n",
            "           -3.3905e-02, -4.0527e-02],\n",
            "          [ 9.8109e-05, -3.5889e-02,  4.2755e-02,  ..., -4.1809e-02,\n",
            "           -6.6895e-02, -1.3519e-02],\n",
            "          [-1.7944e-02,  1.7258e-02,  2.3300e-02,  ..., -6.9397e-02,\n",
            "           -7.0374e-02, -1.4137e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.3435e-02, -9.7070e-01,  1.8242e+00,  ...,  8.9062e-01,\n",
            "           -4.4116e-01,  7.3193e-01],\n",
            "          [ 3.3667e-01, -7.2754e-01,  3.9746e-01,  ...,  1.1582e+00,\n",
            "            7.2217e-01,  4.7388e-01],\n",
            "          [ 7.3291e-01, -6.1865e-01,  9.4629e-01,  ...,  1.0879e+00,\n",
            "            4.8145e-01,  6.8555e-01],\n",
            "          ...,\n",
            "          [-7.3975e-02, -2.3590e-02,  5.0018e-02,  ...,  9.8694e-02,\n",
            "           -5.9204e-02,  1.5674e-01],\n",
            "          [ 5.8746e-03,  2.7176e-02, -2.7771e-02,  ...,  2.9373e-02,\n",
            "           -5.4382e-02, -1.9897e-02],\n",
            "          [-4.9316e-02,  5.5084e-02,  9.5764e-02,  ...,  6.5956e-03,\n",
            "            4.2908e-02, -8.8348e-03]],\n",
            "\n",
            "         [[-5.2734e-01, -1.5039e+00,  1.6250e+00,  ..., -5.0049e-01,\n",
            "            1.7900e+00, -9.5459e-01],\n",
            "          [ 1.1749e-01, -1.1543e+00,  1.2236e+00,  ..., -6.9287e-01,\n",
            "           -4.0088e-01, -3.2690e-01],\n",
            "          [-2.5415e-01, -1.3223e+00,  1.4473e+00,  ..., -5.2979e-01,\n",
            "            9.5117e-01, -7.0801e-01],\n",
            "          ...,\n",
            "          [ 8.8043e-03, -1.0431e-01,  2.9724e-02,  ..., -2.5818e-02,\n",
            "           -6.3515e-03, -6.1157e-02],\n",
            "          [-5.9143e-02, -3.3295e-02,  9.4910e-03,  ..., -4.6478e-02,\n",
            "            1.1047e-02, -7.3853e-02],\n",
            "          [-4.4189e-02, -5.8258e-02,  3.1616e-02,  ..., -5.7098e-02,\n",
            "            8.2703e-02, -3.9581e-02]],\n",
            "\n",
            "         [[-6.5674e-01,  4.7412e-01,  1.8494e-01,  ..., -5.9473e-01,\n",
            "            3.5498e-01,  9.1895e-01],\n",
            "          [-4.6338e-01, -8.2825e-02,  1.5063e-01,  ..., -5.2490e-01,\n",
            "            7.5928e-01,  8.6670e-01],\n",
            "          [ 3.0176e-01, -9.7412e-01, -1.2683e-01,  ..., -4.3652e-01,\n",
            "            1.4463e+00,  9.1211e-01],\n",
            "          ...,\n",
            "          [-3.7781e-02, -5.4199e-02, -5.8990e-02,  ..., -8.1100e-03,\n",
            "            7.0007e-02,  5.8716e-02],\n",
            "          [ 2.6382e-02, -5.5603e-02, -6.2500e-02,  ..., -9.8328e-02,\n",
            "            2.0157e-02, -2.2339e-02],\n",
            "          [-9.3994e-03, -3.0289e-02, -5.4077e-02,  ..., -3.8696e-02,\n",
            "            5.5969e-02,  1.1414e-02]]]], device='cuda:0', dtype=torch.float16)\n",
            "The maximum difference between torch and triton is 0.0009765625\n",
            "True\n",
            "Successfully imported flash_attn_forward.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import triton\n",
        "import triton.language as tl\n",
        "import torch\n",
        "\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "@triton.testing.perf_report(\n",
        "    triton.testing.Benchmark(\n",
        "        x_names=['BATCH', 'N_CTX'],  # Argument names to use as the x-axis\n",
        "        x_vals=[1024, 2048],  # Sequence lengths from 1024 to 16384\n",
        "        line_arg='provider',  # Argument name whose value corresponds to a different line in the plot\n",
        "        line_vals=['triton', 'torch-native', 'torch-eager'],\n",
        "        line_names=['Triton', 'Torch (Native)', 'Torch (Eager)'],\n",
        "        styles=[('blue', '-'), ('green', '-'), ('red', '--')],\n",
        "        ylabel='TFLOPS',\n",
        "        plot_name='flash-attention-performance',\n",
        "        args={'H': 8, 'D_MODEL': 64, 'sm_scale': 0.125},\n",
        "    )\n",
        ")\n",
        "def benchmark(BATCH, N_CTX, H, D_MODEL, sm_scale, provider):\n",
        "    q = torch.randn((BATCH, H, N_CTX, D_MODEL), device=DEVICE, dtype=torch.float16)\n",
        "    k = torch.randn((BATCH, H, N_CTX, D_MODEL), device=DEVICE, dtype=torch.float16)\n",
        "    v = torch.randn((BATCH, H, N_CTX, D_MODEL), device=DEVICE, dtype=torch.float16)\n",
        "\n",
        "    quantiles = [0.5, 0.2, 0.8]\n",
        "    if provider == 'torch-native':\n",
        "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
        "            lambda: torch.nn.functional.scaled_dot_product_attention(q, k, v, is_causal=True, scale=sm_scale),\n",
        "            quantiles=quantiles\n",
        "        )\n",
        "    if provider == 'triton':\n",
        "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
        "            lambda: flash_attn_forward(q, k, v, sm_scale),\n",
        "            quantiles=quantiles\n",
        "        )\n",
        "    if provider == 'torch-eager':\n",
        "        # Manual implementation to show why Flash is better\n",
        "        def eager_attn(q, k, v, scale):\n",
        "            attn = (q @ k.transpose(-2, -1)) * scale\n",
        "            # Simple causal mask for eager\n",
        "            mask = torch.triu(torch.ones(N_CTX, N_CTX, device=DEVICE), diagonal=1).bool()\n",
        "            attn = attn.masked_fill(mask, float('-inf'))\n",
        "            return torch.softmax(attn, dim=-1) @ v\n",
        "\n",
        "        ms, min_ms, max_ms = triton.testing.do_bench(\n",
        "            lambda: eager_attn(q, k, v, sm_scale),\n",
        "            quantiles=quantiles\n",
        "        )\n",
        "\n",
        "    # Compute TFLOPS\n",
        "    # (2 ops for matmul 1, 2 ops for matmul 2) * Batch * Heads * Seq * Seq * Dim\n",
        "    flops_per_matmul = 2.0 * BATCH * H * N_CTX * N_CTX * D_MODEL\n",
        "    total_flops = 2 * flops_per_matmul\n",
        "    return total_flops / (ms * 1e-3) / 1e12\n",
        "\n",
        "# Run it!\n",
        "benchmark.run(show_plots=True, print_data=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "qfg1r6gsDHNR",
        "outputId": "f0d780dc-ec3b-4cb3-8a91-c7472ec248e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 14.56 GiB of which 5.23 GiB is free. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 9.01 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2912398506.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Run it!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_plots\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/testing.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, show_plots, print_data, save_path, return_df, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbench\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbenchmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m                 \u001b[0mresult_dfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbench\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_plots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/testing.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, bench, save_path, show_plots, print_data, diff_col, save_precision, **kwrags)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mrow_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_vals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m                 \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mx_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline_arg\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwrags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     \u001b[0my_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2912398506.py\u001b[0m in \u001b[0;36mbenchmark\u001b[0;34m(BATCH, N_CTX, H, D_MODEL, sm_scale, provider)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         ms, min_ms, max_ms = triton.testing.do_bench(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meager_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/triton/testing.py\u001b[0m in \u001b[0;36mdo_bench\u001b[0;34m(fn, warmup, rep, grad_to_none, quantiles, return_mode)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mdi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_interface\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mdi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2912398506.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         ms, min_ms, max_ms = triton.testing.do_bench(\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meager_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msm_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         )\n",
            "\u001b[0;32m/tmp/ipython-input-2912398506.py\u001b[0m in \u001b[0;36meager_attn\u001b[0;34m(q, k, v, scale)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# Manual implementation to show why Flash is better\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0meager_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0;31m# Simple causal mask for eager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_CTX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_CTX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 14.56 GiB of which 5.23 GiB is free. Including non-PyTorch memory, this process has 9.33 GiB memory in use. Of the allocated memory 9.01 GiB is allocated by PyTorch, and 10.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KgAYBSHENSQH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}